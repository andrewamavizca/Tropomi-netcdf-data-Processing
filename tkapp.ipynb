{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Scenes\n",
    " Used after data has been processed to aid in curating a dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependecy Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from tkinter import Tk, Frame, StringVar, Label, Button, Radiobutton, BOTH, ttk\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Polygon\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = [\n",
    "            ('xch4_corrected', 'f4', ()),\n",
    "            ('latitude_corners', 'f4', (4,)),\n",
    "            ('longitude_corners', 'f4', (4,)),\n",
    "            ('u10', 'f4', ()),\n",
    "            ('v10', 'f4', ()),\n",
    "            ('latitude_center', 'f4', ()),\n",
    "            ('longitude_center', 'f4', ()),\n",
    "            ('scanline', 'i4', ()),\n",
    "            ('ground_pixel', 'i4', ()),\n",
    "            ('time', 'i4', (7,)),\n",
    "            ('solar_zenith_angle', 'f4', ()),\n",
    "            ('viewing_zenith_angle', 'f4', ()),\n",
    "            ('relative_azimuth_angle', 'f4', ()),\n",
    "            ('altitude_levels', 'f4', (13,)),\n",
    "            ('surface_altitude', 'f4', ()),\n",
    "            ('surface_altitude_stdv', 'f4', ()),\n",
    "            ('dp', 'f4', ()),\n",
    "            ('surface_pressure', 'f4', ()),\n",
    "            ('dry_air_subcolumns', 'f4', (12,)),\n",
    "            ('fluorescence_apriori', 'f4', ()),\n",
    "            ('cloud_fraction', 'f4', (4,)),\n",
    "            ('weak_h2o_column', 'f4', ()),\n",
    "            ('strong_h2o_column', 'f4', ()),\n",
    "            ('weak_ch4_column', 'f4', ()),\n",
    "            ('strong_ch4_column', 'f4', ()),\n",
    "            ('cirrus_reflectance', 'f4', ()),\n",
    "            ('stdv_h2o_ratio', 'f4', ()),\n",
    "            ('stdv_ch4_ratio', 'f4', ()),\n",
    "            ('xch4', 'f4', ()),\n",
    "            ('xch4_precision', 'f4', ()),\n",
    "            ('xch4_column_averaging_kernel', 'f4', (12,)),\n",
    "            ('ch4_profile_apriori', 'f4', (12,)),\n",
    "            ('xch4_apriori', 'f4', ()),\n",
    "            ('fluorescence', 'f4', ()),\n",
    "            ('co_column', 'f4', ()),\n",
    "            ('co_column_precision', 'f4', ()),\n",
    "            ('h2o_column', 'f4', ()),\n",
    "            ('h2o_column_precision', 'f4', ()),\n",
    "            ('spectral_shift', 'f4', (2,)),\n",
    "            ('aerosol_size', 'f4', ()),\n",
    "            ('aerosol_size_precision', 'f4', ()),\n",
    "            ('aerosol_column', 'f4', ()),\n",
    "            ('aerosol_column_precision', 'f4', ()),\n",
    "            ('aerosol_altitude', 'f4', ()),\n",
    "            ('aerosol_altitude_precision', 'f4', ()),\n",
    "            ('aerosol_optical_thickness', 'f4', (2,)),\n",
    "            ('surface_albedo', 'f4', (2,)),\n",
    "            ('surface_albedo_precision', 'f4', (2,)),\n",
    "            ('reflectance_max', 'f4', (2,)),\n",
    "            ('convergence', 'i4', ()),\n",
    "            ('iterations', 'i4', ()),\n",
    "            ('chi_squared', 'f4', ()),\n",
    "            ('chi_squared_band', 'f4', (2,)),\n",
    "            ('number_of_spectral_points_in_retrieval', 'i4', (2,)),\n",
    "            ('degrees_of_freedom', 'f4', ()),\n",
    "            ('degrees_of_freedom_ch4', 'f4', ()),\n",
    "            ('degrees_of_freedom_aerosol', 'f4', ()),\n",
    "            ('signal_to_noise_ratio', 'f4', (2,)),\n",
    "            ('rms', 'f4', ())\n",
    "        ]\n",
    "\n",
    "channel_map = {}\n",
    "current_channel = 0\n",
    "\n",
    "for name, field_type, *field_shape in data_type:\n",
    "    # Ensure current_channel is an integer\n",
    "    current_channel = int(current_channel)\n",
    "\n",
    "    if not field_shape:  # Scalar field\n",
    "        channel_map[name] = slice(current_channel, current_channel + 1)\n",
    "        current_channel += 1\n",
    "    else:  # Multi-dimensional field\n",
    "        total_channels = int(np.prod(field_shape))\n",
    "        channel_map[name] = slice(current_channel, current_channel + total_channels)\n",
    "        current_channel += total_channels\n",
    "\n",
    "# Add the normalized methane variable as the last channel\n",
    "channel_map['normalized_ch4'] = slice(current_channel, current_channel + 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_bbox(min_lon, max_lon, min_lat, max_lat, padding=0):\n",
    "    min_lon = np.round(min_lon, 1)\n",
    "    min_lat = np.round(min_lat, 1)\n",
    "    max_lon = np.round(max_lon, 1)\n",
    "    max_lat = np.round(max_lat, 1)\n",
    "    \n",
    "    # Calculate the width and height\n",
    "    width = max_lon - min_lon\n",
    "    height = max_lat - min_lat\n",
    "\n",
    "    # Find the maximum of width and height to maintain an equal aspect ratio\n",
    "    max_dim = max(width, height)\n",
    "\n",
    "    # Calculate the center of the bounding box\n",
    "    center_lon = (min_lon + max_lon) / 2\n",
    "    center_lat = (min_lat + max_lat) / 2\n",
    "\n",
    "    # Calculate half of the max dimension\n",
    "    half_dim = max_dim / 2\n",
    "\n",
    "    # Calculate the new bounding box\n",
    "    new_min_lon = center_lon - half_dim - padding\n",
    "    new_max_lon = center_lon + half_dim + padding\n",
    "    new_min_lat = center_lat - half_dim - padding\n",
    "    new_max_lat = center_lat + half_dim + padding\n",
    "\n",
    "    return [new_min_lon, new_max_lon, new_min_lat, new_max_lat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scene View Gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneViewerApp:\n",
    "    def __init__(self, root, years, locations, channel_map):\n",
    "        self.root = root\n",
    "        self.years = years\n",
    "        self.locations = locations\n",
    "        self.channel_map = channel_map\n",
    "        self.scenes = []\n",
    "        self.current_scene_index = 0  # Start with the first scene\n",
    "        self.labels = []  # List to store labels\n",
    "        self.plume_scenes = []  # List to store only plume scenes\n",
    "        self.plume_count = 0  # Counter for the number of plumes\n",
    "\n",
    "        # Tkinter variables for year and location selection\n",
    "        self.selected_year = StringVar()\n",
    "        self.selected_year.set(self.years[0])  # Default to the first year\n",
    "\n",
    "        self.selected_location = StringVar()\n",
    "        self.selected_location.set(self.locations[0])  # Default to the first location\n",
    "\n",
    "        # Set up the Tkinter interface\n",
    "        self.root.title(\"Scene Viewer\")\n",
    "\n",
    "        # Frame for year and location selection\n",
    "        self.selection_frame = Frame(self.root)\n",
    "        self.selection_frame.pack(side=\"top\", fill=BOTH, padx=10, pady=10)\n",
    "        \n",
    "        # Year selection combo box\n",
    "        self.year_combobox = ttk.Combobox(self.selection_frame, textvariable=self.selected_year, values=self.years)\n",
    "        self.year_combobox.pack(side=\"left\", padx=5)\n",
    "\n",
    "\n",
    "\n",
    "        # Location selection combo box\n",
    "        self.location_combobox = ttk.Combobox(self.selection_frame, textvariable=self.selected_location, values=self.locations)\n",
    "        self.location_combobox.pack(side=\"left\", padx=5)\n",
    "        \n",
    "        #self.channel_view = ttk.Combobox(self.selection_frame, textvariable=self.channel_map, values=list(channel_map.keys()))\n",
    "        #self.channel_view.pack(side=\"left\", padx=5)\n",
    "\n",
    "        # Load scenes button\n",
    "        self.load_button = Button(self.selection_frame, text=\"Load Scenes\", command=self.load_scenes)\n",
    "        self.load_button.pack(side=\"left\", padx=5)\n",
    "\n",
    "        # Frame for navigation controls\n",
    "        self.control_frame = Frame(self.root)\n",
    "        self.control_frame.pack(side=\"top\", fill=BOTH, padx=10, pady=10)\n",
    "\n",
    "        # Previous button\n",
    "        self.prev_button = Button(self.control_frame, text=\"Previous\", command=self.show_previous_scene)\n",
    "        self.prev_button.pack(side=\"left\", padx=5)\n",
    "\n",
    "        # Label to show the current scene index\n",
    "        self.scene_label = Label(self.control_frame, text=\"\")\n",
    "        self.scene_label.pack(side=\"left\", padx=5)\n",
    "\n",
    "        # Next button\n",
    "        self.next_button = Button(self.control_frame, text=\"Next\", command=self.show_next_scene)\n",
    "        self.next_button.pack(side=\"left\", padx=5)\n",
    "\n",
    "        # Plume and No Plume buttons\n",
    "        self.plume_button = Button(self.control_frame, text=\"Plume\", command=lambda: self.label_scene(1))\n",
    "        self.plume_button.pack(side=\"left\", padx=5)\n",
    "\n",
    "        # self.no_plume_button = Button(self.control_frame, text=\"No Plume\", command=lambda: self.label_scene(0))\n",
    "        # self.no_plume_button.pack(side=\"left\", padx=5)\n",
    "\n",
    "        # Save labels and scenes button\n",
    "        self.save_labels_button = Button(self.control_frame, text=\"Save Plumes and Labels\", command=self.save_plumes_and_labels)\n",
    "        self.save_labels_button.pack(side=\"right\", padx=5)\n",
    "\n",
    "        # Plume count label\n",
    "        self.plume_count_label = Label(self.control_frame, text=\"Total Plumes: 0\")\n",
    "        self.plume_count_label.pack(side=\"right\", padx=5)\n",
    "\n",
    "        # Frame for the Matplotlib plot\n",
    "        self.plot_frame = Frame(self.root)\n",
    "        self.plot_frame.pack(side=\"bottom\", fill=BOTH, expand=True)\n",
    "\n",
    "        # Bind arrow keys to navigation functions and 'p' key for labeling as plume\n",
    "        root.bind(\"<Left>\", lambda event: self.show_previous_scene())\n",
    "        root.bind(\"<Right>\", lambda event: self.show_next_scene())\n",
    "        root.bind(\"<p>\", lambda event: self.label_scene(1))  # 'p' key for Plume\n",
    "\n",
    "    def load_scenes(self):\n",
    "        \"\"\"Load scenes based on selected year and location.\"\"\"\n",
    "        year = self.selected_year.get()\n",
    "        location = self.selected_location.get()\n",
    "        directory = f\"data/test/{location}.npy\"\n",
    "        #directory = f\"data/{year}/{location}.npy\"\n",
    "        #directory = f\"/home/sapphire/Desktop/tropomi_scenes/{year}/s5p_l2_ch4_0017_{location}.nc_scenes.npy\"\n",
    "        self.scenes = np.load(directory, allow_pickle=True)\n",
    "        self.current_scene_index = 0  # Reset to the first scene\n",
    "        self.labels = []  # Initialize labels array\n",
    "        self.plume_scenes = []  # Initialize plume scenes list\n",
    "        self.plume_count = 0  # Reset plume count\n",
    "        self.plume_count_label.config(text=\"Total Plumes: 0\")  # Reset plume count display\n",
    "        self.plot()\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\"Plot the current scene using Matplotlib and display it in the GUI.\"\"\"\n",
    "        if hasattr(self, 'canvas'):\n",
    "            self.canvas.get_tk_widget().destroy()\n",
    "\n",
    "        if len(self.scenes) > 0:\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(15, 10), dpi=75)\n",
    "\n",
    "            # Remove padding around the plot\n",
    "            plt.subplots_adjust(left=0.03, right=0.98, top=1, bottom=0, wspace=0.1, hspace=0)\n",
    "            \n",
    "            # Get the current scene's data\n",
    "            scene = self.scenes[self.current_scene_index]\n",
    "\n",
    "            lat_center = scene[self.channel_map['latitude_center']][0]\n",
    "            lon_center = scene[self.channel_map['longitude_center']][0]\n",
    "            #view_value = scene[self.channel_map[self.channel_view.get()]][0]\n",
    "\n",
    "            xch4_corrected = scene[self.channel_map['xch4_corrected']][0]\n",
    "            normalized_ch4 = scene[self.channel_map['normalized_ch4']][0]\n",
    "\n",
    "            min_lat = np.nanmin(lat_center) \n",
    "            max_lat = np.nanmax(lat_center) \n",
    "            min_lon = np.nanmin(lon_center) \n",
    "            max_lon = np.nanmax(lon_center)\n",
    "\n",
    "            lat_corners = scene[self.channel_map['latitude_corners']]\n",
    "            lon_corners = scene[self.channel_map['longitude_corners']]\n",
    "\n",
    "            # Transpose lat/lon corners for plotting\n",
    "            lats = np.transpose(lat_corners, (1, 2, 0))\n",
    "            lons = np.transpose(lon_corners, (1, 2, 0))\n",
    "\n",
    "            # Set color normalization and colormap\n",
    "            vmin = np.nanmin(xch4_corrected)\n",
    "            vmax = np.nanmax(xch4_corrected)\n",
    "            cmap = plt.get_cmap('rainbow')\n",
    "            norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "            # Calculate new bounding box\n",
    "            new_bbox = calculate_new_bbox(min_lon, max_lon, min_lat, max_lat, padding=0.2)\n",
    "\n",
    "            # Extract u10 and v10 from the scene\n",
    "            u10 = scene[self.channel_map['u10']][0]\n",
    "            v10 = scene[self.channel_map['v10']][0]\n",
    "\n",
    "            # Interpolate to fill NaNs in u10\n",
    "            x_valid, y_valid = np.where(~np.isnan(u10))\n",
    "            z_valid = u10[x_valid, y_valid]\n",
    "            grid_x, grid_y = np.mgrid[0:u10.shape[0], 0:u10.shape[1]]\n",
    "            u10_interpolated = scipy.interpolate.griddata((x_valid, y_valid), z_valid, (grid_x, grid_y), method='cubic')\n",
    "            u10_interpolated = np.nan_to_num(u10_interpolated, nan=np.nanmin(u10))\n",
    "\n",
    "            # Interpolate to fill NaNs in v10\n",
    "            x_valid_v, y_valid_v = np.where(~np.isnan(v10))\n",
    "            z_valid_v = v10[x_valid_v, y_valid_v]\n",
    "            v10_interpolated = scipy.interpolate.griddata((x_valid_v, y_valid_v), z_valid_v, (grid_x, grid_y), method='cubic')\n",
    "            v10_interpolated = np.nan_to_num(v10_interpolated, nan=np.nanmin(v10))\n",
    "\n",
    "            # Create 12x12 mesh grid by dividing the data\n",
    "            num_bins = 13\n",
    "            lat_bins = np.linspace(min_lat-1, max_lat+1, num_bins + 1)\n",
    "            lon_bins = np.linspace(min_lon-1, max_lon+1, num_bins + 1)\n",
    "\n",
    "            # Initialize arrays to hold the averaged values\n",
    "            u_avg = np.zeros((num_bins, num_bins))\n",
    "            v_avg = np.zeros((num_bins, num_bins))\n",
    "            lat_avg = np.zeros((num_bins, num_bins))\n",
    "            lon_avg = np.zeros((num_bins, num_bins))\n",
    "\n",
    "            # Iterate through each bin and calculate the mean of the data in that bin\n",
    "            for i in range(num_bins):\n",
    "                for j in range(num_bins):\n",
    "                    lat_mask = (lat_center >= lat_bins[i]) & (lat_center < lat_bins[i + 1])\n",
    "                    lon_mask = (lon_center >= lon_bins[j]) & (lon_center < lon_bins[j + 1])\n",
    "                    mask = lat_mask & lon_mask\n",
    "                    \n",
    "                    if np.any(mask):\n",
    "                        u_avg[i, j] = np.mean(u10_interpolated[mask])\n",
    "                        v_avg[i, j] = np.mean(v10_interpolated[mask])\n",
    "                        lat_avg[i, j] = np.mean(lat_center[mask])\n",
    "                        lon_avg[i, j] = np.mean(lon_center[mask])\n",
    "\n",
    "\n",
    "            # Calculate magnitudes and normalize vectors\n",
    "            magnitude = np.sqrt(u_avg**2 + v_avg**2)\n",
    "\n",
    "            # Avoid division by zero\n",
    "            magnitude[magnitude == 0] = np.nan  # Set zero magnitudes to NaN to avoid division by zero\n",
    "\n",
    "            u_avg_normalized = np.divide(u_avg, magnitude, where=~np.isnan(magnitude))\n",
    "            v_avg_normalized = np.divide(v_avg, magnitude, where=~np.isnan(magnitude))\n",
    "\n",
    "            # Replace NaNs with zeros\n",
    "            u_avg_normalized = np.nan_to_num(u_avg_normalized)\n",
    "            v_avg_normalized = np.nan_to_num(v_avg_normalized)\n",
    "\n",
    "            # Optional: Scale the normalized vectors by a constant factor if needed\n",
    "            scaling_factor = 0.7\n",
    "            u_avg_normalized *= scaling_factor\n",
    "            v_avg_normalized *= scaling_factor\n",
    "\n",
    "            # Use the center of each bin for plotting the vectors\n",
    "            lat_bin_centers = (lat_bins[:-1] + lat_bins[1:]) / 2\n",
    "            lon_bin_centers = (lon_bins[:-1] + lon_bins[1:]) / 2\n",
    "\n",
    "            lon_avg_grid, lat_avg_grid = np.meshgrid(lon_bin_centers, lat_bin_centers)\n",
    "\n",
    "            u_avg_normalized[u_avg_normalized==0] = np.mean(u_avg_normalized)\n",
    "            v_avg_normalized[v_avg_normalized==0] = np.mean(v_avg_normalized)\n",
    "\n",
    "\n",
    "            u_avg[u_avg==0] = np.nan\n",
    "            v_avg[v_avg==0] = np.nan\n",
    "\n",
    "\n",
    "            # Create a Basemap instance\n",
    "            m = Basemap(projection='cyl', ax=ax[0], llcrnrlat= new_bbox[2], urcrnrlat= new_bbox[3], llcrnrlon= new_bbox[0], urcrnrlon= new_bbox[1], suppress_ticks=False, resolution='c')\n",
    "            m.bluemarble()\n",
    "\n",
    "            \n",
    "            # Add polygons for each grid cell\n",
    "            for j in range(lats.shape[0]):\n",
    "                for k in range(lats.shape[1]):\n",
    "                    poly_corners = [\n",
    "                        (lons[j, k, 0], lats[j, k, 0]),  # Top-left\n",
    "                        (lons[j, k, 1], lats[j, k, 1]),  # Top-right\n",
    "                        (lons[j, k, 2], lats[j, k, 2]),  # Bottom-right\n",
    "                        (lons[j, k, 3], lats[j, k, 3])   # Bottom-left\n",
    "                    ]\n",
    "                    color = cmap(norm(xch4_corrected.flatten()[j * 32 + k]))\n",
    "                    poly = Polygon(poly_corners, facecolor=color, edgecolor='grey', linewidth=0.1, alpha=0.9)\n",
    "                    ax[0].add_patch(poly)\n",
    "\n",
    "            # Plot the vectors using quiver\n",
    "            m.streamplot(lon_avg_grid, lat_avg_grid, u_avg, v_avg,latlon=True,color = 'k', density=0.4, linewidth=0.7, broken_streamlines=False)\n",
    "\n",
    "            m.quiver(lon_avg, lat_avg, u_avg, v_avg, latlon=True, scale=10, scale_units='inches', color='black', alpha=0.7, width=0.004, headwidth=3.6, headlength=5, headaxislength=4, pivot='mid', minshaft=2, minlength=1)\n",
    "            ax[0].set_title('XCH4 Corrected')\n",
    "                        \n",
    "            # Plot the data (customize as needed)\n",
    "            ax[1].imshow(xch4_corrected, cmap='rainbow')\n",
    "            ax[1].set_title('XCH4 Corrected')\n",
    "            ax[1].invert_yaxis()\n",
    "            \n",
    "            test1 = np.var(normalized_ch4[normalized_ch4 != 0])*100\n",
    "            test2 = (np.max(normalized_ch4) - np.mean(normalized_ch4[normalized_ch4!=0]))*100\n",
    "            # Plot the data (customize as needed)\n",
    "            ax[2].imshow(normalized_ch4, cmap='rainbow')\n",
    "            ax[2].set_title(f'{test1}\\n{test2}')\n",
    "            ax[2].invert_yaxis()\n",
    "\n",
    "            self.canvas = FigureCanvasTkAgg(fig, master=self.plot_frame)\n",
    "            self.canvas.draw()\n",
    "            self.canvas.get_tk_widget().pack(side=\"top\", fill=BOTH, expand=True)\n",
    "\n",
    "            # Close the figure to free up memory\n",
    "            plt.close(fig)\n",
    "\n",
    "            # Update the scene label\n",
    "            self.scene_label.config(text=f\"Scene {self.current_scene_index + 1} of {self.scenes.shape[0]}\")\n",
    "        else:\n",
    "            self.scene_label.config(text=\"No scenes available.\")\n",
    "\n",
    "    def show_previous_scene(self):\n",
    "        \"\"\"Show the previous scene.\"\"\"\n",
    "        if self.current_scene_index > 0:\n",
    "            self.current_scene_index -= 1\n",
    "            self.plot()\n",
    "\n",
    "    def show_next_scene(self):\n",
    "        \"\"\"Show the next scene.\"\"\"\n",
    "        if self.current_scene_index < self.scenes.shape[0] - 1:\n",
    "            self.current_scene_index += 1\n",
    "            self.plot()\n",
    "\n",
    "\n",
    "    def label_scene(self, label):\n",
    "        \"\"\"Label the current scene as 1 (Plume) or 0 (No Plume).\"\"\"\n",
    "        if label == 1:\n",
    "            self.plume_scenes.append(self.scenes[self.current_scene_index])  # Store only the scene if it's labeled as a plume\n",
    "            self.plume_count += 1\n",
    "            self.plume_count_label.config(text=f\"Total Plumes: {self.plume_count}\")  # Update plume count display\n",
    "\n",
    "        self.labels.append(label)\n",
    "        #print(f\"Labeled scene {self.current_scene_index + 1} as {'Plume' if label == 1 else 'No Plume'}\")\n",
    "\n",
    "        # Automatically move to the next scene after labeling\n",
    "        if self.current_scene_index < len(self.scenes) - 1:\n",
    "            self.show_next_scene()\n",
    "        else:\n",
    "            pass#print(\"All scenes labeled.\")\n",
    "\n",
    "    def save_plumes_and_labels(self):\n",
    "        \"\"\"Save the plume scenes and corresponding labels to separate .npy files.\"\"\"\n",
    "\n",
    "\n",
    "        # Save only the plume scenes\n",
    "        plume_scenes_save_path = f\"data_modded/{self.selected_location.get()}_no_plume_scenes.npy\"\n",
    "        np.save(plume_scenes_save_path, np.array(self.plume_scenes, dtype=object))  # Save plume scenes\n",
    "        #print(f\"Plume scenes saved as '{plume_scenes_save_path}'.\")\n",
    "\n",
    "# Main application\n",
    "if __name__ == \"__main__\":\n",
    "    root = Tk()\n",
    "\n",
    "    #main_directory = '/home/sapphire/Desktop/tropomi_scenes/'\n",
    "    main_directory = f\"data/\"\n",
    "    years = ['2017', '2018', '2019', '2020']\n",
    "    locations = ['test']\n",
    "\n",
    "    for sub_directories in os.listdir(main_directory):\n",
    "        #for sub_sub_directories in os.listdir(main_directory + sub_directories):\n",
    "            #locations.append(sub_sub_directories.split('_')[4].split('.')[0])    \n",
    "        pass\n",
    "\n",
    "    #locations = sorted(locations)\n",
    "\n",
    "    app = SceneViewerApp(root, years, locations, channel_map)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene Counter and Stacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Directory where your .npy files are stored\n",
    "directory = \"data_modded/\"\n",
    "\n",
    "# List to hold all tensors\n",
    "tensors = []\n",
    "\n",
    "# Load each .npy file, check its dtype, and convert if necessary\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        tensor = np.load(os.path.join(directory, filename), allow_pickle=True)\n",
    "        print(f\"{filename} shape {tensor.shape}\")\n",
    "        \n",
    "        # Check if the tensor is not already a float type\n",
    "        if not np.issubdtype(tensor.dtype, np.floating):\n",
    "            tensor = tensor.astype(np.float64)  # Convert to float32 if not already a float type\n",
    "            #print(f\"Converted {filename} to dtype {tensor.dtype}\")\n",
    "        tensors.append(tensor)\n",
    "        #tensors.append(tensor)\n",
    "        # percent = np.round(sum(tensors)/2242, 2)\n",
    "        # remaining = 2242 - sum(tensors)\n",
    "# print(f'{int(percent*100)} % .... {sum(tensors)} of 2242. Remaining: {remaining}')\n",
    "\n",
    "\n",
    "# # # Ensure the output directory exists\n",
    "output_directory = \"data_modded/\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# # # # Save the combined array to a new .npy file\n",
    "output_filename = os.path.join(output_directory, \"noPlumes_final.npy\")\n",
    "np.save(output_filename, np.concatenate(tensors, axis=0), allow_pickle=True)\n",
    "\n",
    "# print(f\"Combined tensor saved to {output_filename} with shape {combined_tensor.shape} and dtype {combined_tensor.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load('main_data/noPlumes_final.npy', allow_pickle=True).shape\n",
    "# np.load('main_data/FINAL_SET_GOOD_PLUMES.npy', allow_pickle=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_scene(scene, angle):\n",
    "    return scipy.ndimage.rotate(scene, angle, axes=(-2, -1), reshape=False)\n",
    "\n",
    "# Function to flip the scene horizontally\n",
    "def flip_scene_horizontally(scene):\n",
    "    return np.flip(scene, axis=-1)\n",
    "\n",
    "# Function to flip the scene vertically\n",
    "def flip_scene_vertically(scene):\n",
    "    return np.flip(scene, axis=-2)\n",
    "\n",
    "# Function to apply rotations and flips to a tensor\n",
    "def augment_tensor(tensor):\n",
    "    augmented_tensors = []\n",
    "\n",
    "    for scene in tensor:\n",
    "        # Original scene\n",
    "        augmented_tensors.append(scene)\n",
    "        \n",
    "        # Apply rotations\n",
    "        for angle in [90, 180, 270]:\n",
    "            rotated_scene = rotate_scene(scene, angle)\n",
    "            augmented_tensors.append(rotated_scene)\n",
    "        \n",
    "        # Apply horizontal flip\n",
    "        flipped_h = flip_scene_horizontally(scene)\n",
    "        augmented_tensors.append(flipped_h)\n",
    "        \n",
    "        # Apply vertical flip\n",
    "        flipped_v = flip_scene_vertically(scene)\n",
    "        augmented_tensors.append(flipped_v)\n",
    "        \n",
    "    # Combine augmented scenes into a new tensor\n",
    "    return np.array(augmented_tensors)\n",
    "\n",
    "# Load your combined tensor\n",
    "tensor = np.load(\"combined_scenes.npy\")\n",
    "\n",
    "# Augment the tensor with flips and rotations\n",
    "augmented_tensor = augment_tensor(tensor)\n",
    "\n",
    "# Save the augmented tensor\n",
    "np.save(\"augmented_scenes.npy\", augmented_tensor)\n",
    "\n",
    "print(f\"Augmented tensor shape: {augmented_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    " - Noticed that taking the variance of the normalized matrix not inlcuding values that are 0, scenes with plumes tend to apear when the value for this above 1.\n",
    "\n",
    " - When we take the second highest value in the scene and subtract the mean of the normal ch4 matrix values above 0.50% tend to include plumes. Values below tend not to.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
